# HW4：Speaker Identification
作业是一个多分类的任务，训练集有56666个数据，测试集有4000个数据，一共有600个标签。
## 改写Conformer
将模型的encoder部分从transformer改写成Conformer。注意的是transformer的传入参数是(seq_len, batch_size, d_model)，但是conformer的是(batch_size, seq_len, d_model)
transformer部分：
```Python
class Classifier(nn.Module):
    def __init__(self, d_model=80, n_spks=600, nhead=2,dropout=0.1):
        super().__init__()
        self.prenet = nn.Linear(40, d_model)
        self.encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, dim_feedforward=256, nhead=2)
        self.pred_layer = nn.Sequential(
            nn.Linear(d_model, d_model),
            nn.Sigmoid(),
            nn.Linear(d_model, n_spks),)
```
改写后：
```Python
class Classifier(nn.Module):
    def __init__(self, d_model=80, n_spks=600, nhead=2,dropout=0.1):
        super().__init__()
        self.prenet = nn.Linear(40, d_model)
	    self.encoder=Conformer(input_dim=d_model,
		    num_heads=nhead,ffn_dim=256,
		    num_layers=2,dropout=dropout)
        self.selfattention_pooling=SelfAttentionPooling(
	        d_model=d_model,nhead=nhead)
	    ...
```
## 添加自注意力池化层
在encoder和dnn之间添加一层自注意力池化层，更容易捕捉到全局信息。需要注意的是，在forward中要求的输入是(batch_size, seq_len, d_model)
![Pasted image 20240719213601](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240719213601.png)
```Python
class SelfAttentionPooling(nn.Module):
    def __init__(self, d_model, nhead):
        super(SelfAttentionPooling, self).__init__()
        self.attention = nn.MultiheadAttention(embed_dim=d_model, num_heads=nhead)
    def forward(self, x):
        attn_output, attn_weights = self.attention(x, x, x)
        global_feature = attn_output.mean(dim=0)
        return global_feature
class Classifier(nn.Module):
    def __init__(self, d_model=80, n_spks=600, nhead=2,dropout=0.1):
	...    
self.selfattention_pooling=SelfAttentionPooling(d_model=d_model,nhead=nhead)
	...
```
## 更改Loss函数
将loss函数从交叉熵改为AM-Softmax Loss。
原始的CrossEntropyLoss：
```Python
criterion = nn.CrossEntropyLoss()
```
更改后：
```Python
def am_softmax(logits, labels, s=30.0, m=0.35):
    index = torch.arange(0, logits.size(0), dtype=torch.long)
    correct_class_logits = logits[index, labels]
    margin_logits = correct_class_logits - m
    scaled_logits = logits * (1 - labels.unsqueeze(1)) + margin_logits.unsqueeze(1) * labels.unsqueeze(1)
    scaled_logits *= s
    loss = F.cross_entropy(scaled_logits, labels)
    return loss
```
# HW5：Machine Translation
## 修改学习率
将固定的学习率修改为以下：
$$lrate = d_{\text{model}}^{-0.5}\cdot\min({step\_num}^{-0.5},{step\_num}\cdot{warmup\_steps}^{-1.5})$$
代码
```Python
def get_rate(d_model, step_num, warmup_step):
    lrate = (d_model ** -0.5) * min(step_num ** -0.5, step_num * (warmup_step ** -1.5))
    return lrate
```
## 更换模型
将rnn更换成transformer。
```Python
encoder = TransformerEncoder(args, src_dict, encoder_embed_tokens)
decoder = TransformerDecoder(args, tgt_dict, decoder_embed_tokens)
```
## 回译back-translation
```Python
def translate(text, model, tokenizer):
    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)
    outputs = model.generate(**inputs)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

def back_translate(text):
    translated_zh = translate(text, model_en_zh, tokenizer_en_zh)
    back_translated_en = translate(translated_zh, model_zh_en, tokenizer_zh_en)
    return back_translated_en
```
# HW6：Diffusion Model
## 数据增强
在读取数据集时数据增强
```Python
self.transform = T.Compose([
            T.Resize(image_size),
            T.RandomHorizontalFlip(p=0.5),# 随机水平翻转
            T.ColorJitter(brightness=0.5,contrast=0.5,saturation=0.5,hue=0.1),
            T.ToTensor()
        ])
```
## 使用sigmoid_beta_schedule
在diffusion模型中使用sigmoid_beta_schedule
```Python
def sigmoid_beta_schedule(timesteps, start=-3., end=3., tau=0.7, clamp_min=1e-5):
    steps = timesteps + 1
    t = torch.linspace(0, timesteps, steps) / timesteps
    v_start = torch.tensor(start / tau).sigmoid()
    v_end = torch.tensor(end / tau).sigmoid()
    alphas_cumprod = (-((t * (end - start) + start) / tau).sigmoid() + v_end) / (v_end - v_start)
    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]
    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])
    return torch.clip(betas, clamp_min, 1.)
```
然后在配置中修改`beta_schedule = 'sigmoid'`
