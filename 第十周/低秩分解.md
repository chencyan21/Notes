# 命令行使用
命令行输入：
```Bash
python3 scripts/decomp.py [-p PATH] [-d DECOMPTYPE] [-m MODEL] [-r CHECKPOINT] [-s STATEDICT] [-v]
```
在`decomp`文件中，处理参数得到以下变量：
```
use_cp：分解方式，默认cp
use_model：使用现有模型
use_param：用于恢复之前的重训练状态，这意味着程序会从之前的状态继续训练，而不是从头开始
use_state：用于使用之前完成的重训练状态，这意味着程序会使用已经训练好的模型，而不是继续训练。
eval_mode：训练或是验证模式
arch：默认为resnet50
```
# 数据集准备
在huggingface上下载小型的imagenet数据集`zh-plus/tiny-imagenet`，下载后的文件格式为parquet。由于源代码中需要的文件格式为图片，所以需要将parquet中的图片提取出来保存到本地。
使用`pyarrow.parquet`库中的函数`read_table`读取文件，读取到图片为字节格式，需要通过pillow库的Image转为图片格式保存：
```Python
import pyarrow.parquet as pq
from PIL import Image
import os
import io
# 读取 Parquet 文件
file_path = 'dataset/val/val.parquet'
table = pq.read_table(file_path)
# 将数据转换为 Pandas DataFrame
df = table.to_pandas()
# 遍历每一行数据
for index, row in df.iterrows():
    image = row['image']  # 提取图像对象
    label = row['label']  # 提取标签
    # 构建保存图像的目录
    save_dir = f"dataset/val/{label}"
    os.makedirs(save_dir, exist_ok=True)
    # 保存图像到对应的目录中
    save_path = os.path.join(save_dir, f"image_{index}.jpg")
    image_stream = io.BytesIO(image['bytes'])
    # 使用 Pillow 从二进制流中打开图像
    image = Image.open(image_stream)
    image.save(save_path)
    print(f"Saved image {index} to {save_path}")
```
# 模型及相关配置
使用以下命令创建模型：`net = models.__dict__[args.arch](pretrained=True)`
然后使用`gen_loaders`函数读取数据集，并拆分出`train_loader`和`val_loader`
## `decomp_resnet`函数
在`decomp_resnet`函数中，将对resnet网络中的瓶颈层进行分解。函数接受三个参数：`net`（ResNet 网络）、`rank_func`（用于计算瓶颈层的秩的函数）和 `decomp_func`（用于进行分解的函数）。

`rank_funk`函数是`est_rank`函数，用于估计神经网络层的秩。它通过对层的权重数据 (`W`) 进行矩阵分解，得到两个对角矩阵 (`diag_0` 和 `diag_1`)，然后返回这两个矩阵的最大秩，并将其向上舍入到最接近的 16 的倍数。
```Python
def est_rank(layer):
    W = layer.weight.data
    mode3 = tl.base.unfold(W, 0)
    mode4 = tl.base.unfold(W, 1)
    diag_0 = EVBMF(mode3)
    diag_1 = EVBMF(mode4)
    # round to multiples of 16
    return int(np.ceil(max([diag_0.shape[0], diag_1.shape[0]]) / 16) * 16)
```
> `EVBMF`函数实现了经验变分贝叶斯矩阵分解（Empirical Variational Bayes Matrix Factorization，简称 EVBMF）的解析解。EVBMF 是一种用于降维和数据压缩的矩阵分解方法，它通过最大化似然函数来估计矩阵的低秩近似。

`decomp_func`默认为`torch_cp_decomp`函数，实现了张量分解中的CP分解算法，将CNN分解为三个更小的卷积层。输入一个CNN层和一个分解的秩，函数会返回三个新的卷积层，分别是点卷积层（Pointwise Convolutional Layer）、深度卷积层（Depthwise Convolutional Layer）和另一个点卷积层。这些新层的权重是通过CP分解算法计算得到的。

在`decomp_resnet`函数中，首先遍历ResNet网络的每个层，对于每个层，如果它有子层，则进入该层，遍历该层的每个瓶颈，计算瓶颈的分解秩并根据其类型（整数或列表）执行CP分解，如果分解后的结果小于原始的输入和输出通道数，则打印分解等级并执行分解操作，更新瓶颈的 `conv2` 层，最后返回更新后的 ResNet 网络。
```Python
from functools import reduce
from torch import nn
def decomp_resnet(net, rank_func, decomp_func):
    mulfunc = (lambda x,y:x*y)
    for n, m in net.named_children():
        num_children = sum(1 for i in m.children())
        if num_children != 0:
            # in a layer of resnet
            layer = getattr(net, n)
            # decomp every bottleneck
            for i in range(num_children):
                bottleneck = layer[i]
                conv2 = getattr(bottleneck, 'conv2')
                rank = rank_func(conv2)
                if type(rank) == int:
                    # in this case cp decomp is used
                    reduced = rank**2
                else:
                    # tucker decomp in this case
                    reduced = reduce(mulfunc, rank)
                if reduced < \
                reduce(mulfunc, [conv2.in_channels, conv2.out_channels]):
                    print('ranks for bottleneck {} in {}: {}'\
                    .format(i, n, rank))
                    new_layers = decomp_func(conv2, rank) 
                    setattr(bottleneck, 'conv2', nn.Sequential(*new_layers))
                del conv2
                del bottleneck
            del layer
    return net
```

得到更新后的模型后，设置相关超参数，优化器使用SGD随机梯度下降，loss使用交叉熵，准备下一阶段的训练。
# 模型训练
模型训练与普通的训练类似，首先调用`validate`比对验证集结果，计算准确率。
然后模型开始训练：
```Python
inputs, labels = data
# wrap inputs and labels in variables
inputs, labels = Variable(inputs).cuda(), \
Variable(labels).cuda()
# zero the param gradient
optimizer.zero_grad()
# forward + backward + optimize
outputs = model(inputs)
loss = criterion(outputs, labels)
result = accuracy(outputs.data, labels.data, topk)
```
**注**：模型训练是一个while为True的循环，需要手动停止。
模型输出结果：![Pasted image 20240831131030](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240831131030.png)
# 代码报错修改
1. `last, first, vertical, horizontal = parafac(W, rank=rank, init='random') ValueError: not enough values to unpack (expected 4, got 2)`
 - 解决方案：`parafac`现在返回的是weights和factors，而`last, first, vertical, horizontal`是factors元组的内容，只需要返回factors即可：`last, first, vertical, horizontal = parafac(W, rank=rank, init='random')[1]`
2. `raise ValueError("Optimisation bounds must be scalars"`
 - 解决方案：在TVBMF文件中，将`[lower_bound, upper_bound]`更改为`np.array([lower_bound, upper_bound])`
3. `RuntimeError: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.`
 - 解决方案：在generic_training文件中将`correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)`修改为`correct_k = correct[:k].contiguous().view(-1).float().sum(0, keepdim=True)`
