# 15 Add Knowledge to Language Models
## Recap LMs
标准的语言模型：可预测文本序列中的下一个单词，并计算一个序列的概率。
```
The students opened their [books].
```
最近，屏蔽语言模型（如BERT）改用双向context来预测文本序列中的masked token。
```
I [MASK] to the [MASK] --> I went to the store.
```
这两种类型的语言模型都可以在大量未标注文本的基础上进行训练。

传统上，LMs常用于生成文本或者评估文本概率的任务：
* 总结
- 对话
- 自动完成
- 机器翻译
- 流畅性评估
当前的LMs通常用于生成文本的预训练表示，这些表示为下游NLP任务编码了某种语言理解概念。

如果LM在大量文本上进行训练，能被用做知识库吗？
## What does a language model know?
语言模型的预测通常是有意义的（如正确的类型），但并非都符合事实。（回答可能包含错误答案，但是回答都是符合常识的）。
该现象发生的原因：
1. 未遇见的事实：一些facts模型在训练的时候没有见过
2. 出现次数较少的事实：模型在训练期间没有看到足够多的例子来记住该facts
3. 模型敏感程度：模型可能在训练时见过该fact，但是对prompt的措辞很敏感
	1. 使用“x was created in y”回答不正确，但是用“x was made in y”回答正确。
使用传统的知识库：知识图三元组来存储知识。![Pasted image 20240815185310](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240815185310.png)
使用语言模型作为知识库查询：
![Pasted image 20240815201439](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240815201439.png)
**Advantages of language models over traditional KBs**：
1. LM在大量的非结构化和未标记文本进行预训练
- 传统KB需要手动标注或复杂的NLP管道来填充
LM支持更灵活的自然语言查询
然而，将LM用作KB还面临许多挑战：
- 难以解释（即为什么LM会产生答案）
- 难以信任（即LM可能会得出一个现实的、不正确的答案）
- 难以修改（即不易删除或更新LM中的知识）

## Techniques to add knowledge to LMs
向LM添加知识的技术：
1. 添加预训练实体嵌入：
	1. ERNIE
	2. KnowBERT
2. 使用外部存储：
	1. KGLM
	2. kNN-LM
3. 修改训练数据
	1. WKLM
	2. ERNIE (another!), salient span masking
### 方法1：添加预训练嵌入
关于世界的现实通常用**实体**表示，但预训练的词嵌入并没有实体这个概念，例如，USA/America表示相同的实体但是却有着不同的词嵌入。
解决方案：给每一个实体分配一个嵌入，称为**实体嵌入**。如果能很好地进行实体链接，实体嵌入对LM可能会很有用。
实体链接（entity linking）：将文本中的提及到的内容链接到知识库中的实体。
![Pasted image 20240816112907](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240816112907.png)
实体链接需要正确找出这些文本中不确定的内容应该链接到知识库中的哪一个实体。

通过一个fusion layer结合context和实体信息。$$h_j=F(W_t w_j+W_e e_k+b)$$
我们假定句子中的实体和词语之间存在已知的对齐关系，即$e_k=f(w_j)$
- $w_j$是词j在词序列中的嵌入（Washington）
- $e_k$是相应的实体嵌入（George Washington）

#### ERNIE: Enhanced Language Representation with Informative Entities
模型架构：
1. 文本encoder：句子中单词的多层双向transformer编码器
2. Knowledge encoder：由以下堆叠块组成：
	1. 实体嵌入和token/subword嵌入的两个多头注意力
	2. 一个fusion layer用于结合多头注意力层的输出
![Pasted image 20240816152026](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240816152026.png)
![Pasted image 20240816152124](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240816152124.png)

使用以下三个任务进行预训练：
1. Bert任务（两个）：**Masked language model** and **next sentence prediction**
2. DEA任务：随机屏蔽token-实体排列，并从序列中的实体中预测token的对应实体
![Pasted image 20240816153236](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240816153236.png)
该模型的strengths：
1. 通过fusion layer和一个知识预训练任务结合实体和上下文信息
2. 提高下游知识驱动任务的性能
remaing challenges：
1. 需要带有**实体标注**的文本数据
2. 需要对模型进行进一步预训练（knowledge encoder）
#### Jointly learn to link entities with KnowBERT
idea：预训练一个集成实体链接器 (EL)作为BERT扩展。
![Pasted image 20240816153349](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240816153349.png)
在下游任务中，EL会预测实体，因此不需要实体注释
学习EL可以更好地编码知识，与 ERNIE 相比，学习EL在下游任务的成绩有所提高
与ERNIE一样，KnowBERT也使用fusion layer将实体信息和context信息结合起来
并增加了knowledge pretraining task。
### 方法2：使用外部存储器
在上一个方法中，如果需要修改知识库，就需要重新训练实体嵌入，然后重新训练模型。
让模型访问外部存储器（键值存储，可访问G三元组或上下文信息），可更好地支持注入和更新事实知识，通常不需要更多的预训练，更易于解释。
#### Barack's Wife Hillary: Using Knowledge-Graphs for Fact-Aware Language Modeling (KGLM)
idea：在知识图谱上调节语言模型
使用实体信息，通过计算下列式子预测下一个词：$$P(x^{(t+1)},\varepsilon^{(t+1)}|x^{(t)},...,x^{(1)},\varepsilon^{(t)},\varepsilon^{(1)})$$
其中，$\varepsilon^{(t)}$是KG实体集在时间步t中提及的实体。
在迭代序列时建立本地知识图谱
- 本地KG：完整KG的子集，只包含与序列相关的实体

![Pasted image 20240816160018](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240816160018.png)在以上例子中，由于句子中的关系并不在KG中存在，所以KGLM需要先预测出得分最高的父实体是Super Mario Land，然后得分最高的关系是publisher。根据得到的结果使用KG三元组得到尾部实体为Nintendo。

具体步骤：
获取相关实体（在本地KG）
- 使用LSTM隐状态、以及预训练的实体和关系嵌入查找本地KG中得分最高的父实体和关系
- $P(p_t)=softmax(v_p\dot h_t)$，其中$p_t$是父实体，$v_p$是相应实体嵌入，而$h_t$是LSTM隐状态
- **下一个实体**：来自KG三元组（父实体、关系、尾实体）的尾实体
- **下一个词**： 词典中最有可能的下一个标记（可扩展到包括实体别名）

预测新实体（不在本地KG）
- 使用LSTM隐状态和预训练实体嵌入在完整的KG中找到得分最高的实体。
- **下一个实体**：完整知识图中得分最高的实体
- **下一个词**：词典中最有可能的下一个标记（可扩展到包括实体别名）

非实体的情况：
- **下一个实体**：无
- **下一个词**：标准词典中的下一个token
![Pasted image 20240816165105](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240816165105.png)

Strengths：
- 知识修改/更新知识（可以从模型预测中直接看到）

local KG和full KG的区别：
local KG是full KG的一个子集，它只应该由在序列中出现过的实体及其相关实体组成，同时还会从full KG中复制所有的边/关系。如果使用local KG，信号会更强（？）。在softmax中，只需要预测local KG中的父实体，相比于full KG的计算量更小。
#### Nearest Neighbor Language Models (kNN-LM)
idea：学习文本序列之间的相似性比预测下一个单词更容易
将文本序列的所有表示形式存储在近邻数据存储库中
推理阶段：
1. 在数据存储中找出k个最相似的文本序列
2. 检索k个序列的相应值（即下一个词
3. 结合kNN概率和LM概率进行最终预测
$$P(y|x)=\lambda P_{kNN}(y|x)+(1-\lambda)P_{LM}(y|x)$$
![Pasted image 20240816171715](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240816171715.png)

### 方法3：修改训练数据
上述的方法通过预训练嵌入和外部存储明确地纳入知识。
通过屏蔽或破坏数据，引入需要事实知识的额外训练任务，非结构化文本也能隐含知识
Advantages：
- 无额外内存/计算要求
- 无需修改架构
#### Pretrained Encyclopedia: Weakly Supervised Knowledge-Pretrained Language Model (WKLM)
idea：训练模型以区分真假知识
用指代同一类型不同实体的提法替换文本中的提到的内容，破坏数据创建负面知识陈述
- 模型预测实体是否被替换
- 类型约束旨在执行语言正确的句子
loss：![Pasted image 20240816173627](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240816173627.png)
#### ERNIE: Enhanced Representation through Knowledge Integration
Salient span masking显著跨度掩蔽（掩蔽一系列短语）：在检索和QA任务上，显著广度掩蔽已被证明优于其他掩蔽/损坏策略。![Pasted image 20240816174338](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240816174338.png)
## Evaluating knowledge in LMs
### LAnguage Model Analysis (LAMA) Probe
不用二外的训练和预训练，现成的语言模型中已经包含了多少关系（常识和事实）知识？
首先手动构建一组完形语句，以评估模型预测缺失标记的能力。
根据KG三元组和问答对生成完形语句
将LM与有监督的关系提取 (RE) 和问题解答系统进行比较
目标：评估现有预训练LM中的知识（这意味着它们可能有不同的预训练语料库）。
缺点：
- 很难理解为什么模型在运行时表现良好。
- 语言模型可能只识别到了主体和客体的表面相似性
- 模型对语句的措辞敏感（这意味着探测结果是LM中编码知识的下限）
**A More Challenging Probe: LAMA-UnHelpful Names (LAMA-UHN)**
idea：从LAMA中删除不需要相关知识便可以直接回答的例子。
观测结果：
- BERT 可依靠实体的表面形式进行预测（而非利用知识）

处理措辞敏感问题：
从维基百科中挖掘模板，生成更多LAMA提示，并利用反向翻译生成意译提示。组合提示，增加事实出现的背景多样性
![Pasted image 20240816180307](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240816180307.png)
# 16 Social & Ethical Considerations in NLP Systems
语言与人有关，具有社会意义并包含人类偏见。

IQ分类器：有悖于道德

AI Gaydar：从脸判断性取向![Pasted image 20240817235815](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240817235815.png)
收集到的数据是合法的，但并不合乎道德。
公开的数据不等于可以被宣传（public不等于publicized）
数据集只包含白人，充满偏见

错误分类的成本并不等同于正确分类的![Pasted image 20240817235823](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240817235823.png)

# 17 Model Analysis and Explanation
查看模型和执行分析的方法：
1. 作为概率分布和决策函数的神经模型
2. 作为深度和时间向量表示序列
3. 参数权重、特定机制，如注意力、dropout

将模型评估作为模型分析：
在研究模型的行为时，我们并不关心模型正在使用的机制而关心的是模型在感兴趣的情况下是如何表现的？假设已经在某种分布的样本$(x,y)~D$上训练了模型。通过测试机的结果比对查看模型效果。

自然语言推理中的模型评估即模型分析，如果模型使用简单的启发式方法就能获得很好的准确性，那么需要专门设计测试集用于测试神经模型的特定技能或能力。
例如，HANS：（NLI 系统启发式分析）测试 NLI 中的语法启发式方法
1. 词汇重叠：假设前提蕴含由前提中的词语构建的所有假设
2. 子序列：假设前提蕴含其所有连续的子序列。
3. 句子结构：假设前提包含其解析树中的所有完整子树。

人类评估语言行为：
一个方法是使用最小对，一个听起来正常的句子，通过修改一个词或尽可能少的词来听起来unacceptable
![Pasted image 20240817235830](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240817235830.png)

## Careful test sets as unit test suites: CheckListing
最低限度的功能测试：针对特定行为的小测试集。
![Pasted image 20240817235838](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240817235838.png)
Ribeiro提出一个具有为NLP模型构建测试用力的框架，帮助工程师找到bug。

在广泛的任务范围内，域内测试集上的高模型精度并不意味着模型在其他“合理的”域外示例上也会表现良好。
一种思考方式是：模型似乎在学习数据集(如MNLI)，而不是学习任务(如人类如何进行自然语言推理)。

在LSTM中，context中打乱或删除k个单词来查看对loss影响，如果准确度未受到影响，也就意味模型并没有使用context。
下图说明：该LSTM模型中上下文中超过了50个单词的内容可以完全打乱，对模型并没有任何影响。模型确实在使用long memory。
![Pasted image 20240817235844](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240817235844.png)

通过减少输入进行解释：在提问中删除最小的部分来得到相同的答案：![Pasted image 20240817235853](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240817235853.png)
该方法的idea：运行输入突出法，迭代删除最不重要的单词。
![Pasted image 20240817235859](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240817235859.png)


