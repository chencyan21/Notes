# Python包
由于新版的`torchtext`已经废弃了代码中的使用的大部分接口，所以需要安装旧版本的`torchtext`：
```Bash
pip install torchtext==0.5.0
```
在`TEXT = data.Field(tokenize='spacy',tokenizer_language='en_core_web_sm')`中会用到Spacy包，同时会加载en_core_web_sm语言模型，需要先从github上使用命令行下载：
```Bash
pip install spacy
python -m spacy download en_core_web_sm
```
# Vocab建立
从预训练的glove模型词向量中，将当前corpus的词向量抽取出来，构成当前 corpus 的 Vocab，每个单词有100维。
```Python
TEXT.build_vocab(train_data, max_size=25000, vectors="glove.6B.100d", unk_init=torch.Tensor.normal_)
LABEL.build_vocab(train_data)
```
因为添加了`<unk>`和`<pad>`，所以vocab一共有25002个tokens。
# 模型
## Word Averaging模型
该模型简单有效，基本步骤：
1. 词向量表示：将每个词通过glove模型转为词向量
2. 求和平均：将给定的句子的词向量求和平均
3. fc层：再通过两个fc层后使用softmax输出预测结果。
### 结果输出：
![Pasted image 20240803112244](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240803112244.png)在test数据集上表现较好。
![Pasted image 20240803112305](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240803112305.png)

## RNN模型
首先将输入的token通过embedding层转为嵌入向量，使用dropout，将向量输入到LSTM中，得到`output`、`hidden`和`cell`，对于双向LSTM，会有两个隐藏状态，需要将它们拼接在一起，拼接后的隐层状态再通过fc层输出预测结果。
### 结果输出
相比于word averaging的简单模型，rnn的准确性更高。
![Pasted image 20240803122831](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240803122831.png)

## CNN模型
cnn模型中将嵌入向量通过卷积后，再进行max pool操作，将结果通过fc层输出。
### 结果输出
cnn模型复杂度介于word averaging模型和rnn之间，相类似的测试结果也介于二者之间。
![Pasted image 20240803123013](https://cyan-1305222096.cos.ap-nanjing.myqcloud.com/Pasted%20image%2020240803123013.png)